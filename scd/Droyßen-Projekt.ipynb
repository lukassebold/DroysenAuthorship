{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314adbee-4528-45b6-a661-f44a7609d52a",
   "metadata": {},
   "source": [
    "# Droyßen Authorship-Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123014d-6969-4bc2-9729-a0ae5e17ae83",
   "metadata": {},
   "source": [
    "## Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c711300-8e23-4fe9-8527-6024194f5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import scipy.spatial.distance as scidist\n",
    "import sklearn.decomposition\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3812cf1-bcec-4bc5-af4b-c226b9483546",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32198ece-955d-49cb-b908-cbe0167fb6b8",
   "metadata": {},
   "source": [
    "### Helferfunktion zum Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2586f8b7-1be5-426d-b9b9-ae1a83e83338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directory(directory, max_length):\n",
    "    documents, authors, titles = [], [], [] \n",
    "    for filename in os.scandir(directory):\n",
    "        if not filename.name.endswith('.txt'):\n",
    "            continue\n",
    "        author, _ = os.path.splitext(filename.name)\n",
    "\n",
    "        with open(filename.path) as f:\n",
    "            contents = f.read()\n",
    "        lemmas = contents.lower().split()\n",
    "        start_idx, end_idx, segm_cnt = 0, max_length, 1\n",
    "\n",
    "        # extract slices from the text:\n",
    "        while end_idx < len(lemmas):\n",
    "            documents.append(' '.join(lemmas[start_idx:end_idx]))\n",
    "            authors.append(author[0])\n",
    "            title = filename.name.replace('.txt', '').split('_')[1]\n",
    "            titles.append(f\"{title}-{segm_cnt}\")\n",
    "\n",
    "            start_idx += max_length\n",
    "            end_idx += max_length\n",
    "            segm_cnt += 1\n",
    "\n",
    "    return documents, authors, titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8914e3ae-d8ab-4f75-8e0c-01694cd6a407",
   "metadata": {},
   "source": [
    "Vokabular: verschiedene Listen: Ausgangspunkt: most frequent words, dann schrittweise neue Listen erstellen mit Wörtern, die man rausnimmt (mit Begründung im Text), dann über Code von Ursprungsliste \"abziehen\"\n",
    "Anders als Kestemon: dort war die Liste mit \"##\" aussortiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b6412-f51c-4282-a045-9c608f045070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
